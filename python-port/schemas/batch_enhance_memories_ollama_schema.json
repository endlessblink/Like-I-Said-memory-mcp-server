{
  "name": "batch_enhance_memories_ollama",
  "description": "Batch process memories using local AI (Ollama) for privacy-focused title/summary generation. Processes large numbers of memories efficiently without external API calls.",
  "inputSchema": {
    "type": "object",
    "properties": {
      "project": {
        "type": "string",
        "description": "Filter by project name (optional)"
      },
      "category": {
        "type": "string",
        "description": "Filter by category (optional)"
      },
      "limit": {
        "type": "number",
        "description": "Maximum number of memories to process (default: 50)"
      },
      "skip_existing": {
        "type": "boolean",
        "description": "Skip memories that already have titles/summaries (default: true)"
      },
      "model": {
        "type": "string",
        "description": "Ollama model to use (default: llama3.1:8b)"
      },
      "batch_size": {
        "type": "number",
        "description": "Number of memories to process in parallel (default: 5)"
      }
    }
  }
}