{
  "name": "check_ollama_status",
  "description": "Check if Ollama server is running and list available models for local AI processing.",
  "inputSchema": {
    "type": "object",
    "properties": {
      "show_models": {
        "type": "boolean",
        "description": "Whether to list available models (default: true)"
      }
    }
  }
}